2025-08-12 10:08:20,402 - evalscope - INFO - Starting benchmark with args: 
2025-08-12 10:08:20,403 - evalscope - INFO - {
    "model": "deepseek-ai/DeepSeek-V3",
    "model_id": "DeepSeek-V3",
    "attn_implementation": null,
    "api": "openai",
    "tokenizer_path": "C:\\Users\\lenovo\\Desktop\\data_process",
    "port": 8877,
    "url": "https://api.siliconflow.cn/v1/chat/completions",
    "headers": {
        "Authorization": "Bearer sk-rjacpshuajlbslogyccxedlftfcjjkptfiejhdrwkjrvyxea"
    },
    "connect_timeout": 600,
    "read_timeout": 600,
    "api_key": null,
    "no_test_connection": false,
    "number": 1,
    "parallel": 1,
    "rate": -1,
    "sleep_interval": 5,
    "log_every_n_query": 10,
    "debug": false,
    "wandb_api_key": null,
    "swanlab_api_key": null,
    "name": null,
    "outputs_dir": "outputs\\20250812_100820\\DeepSeek-V3",
    "max_prompt_length": 256,
    "min_prompt_length": 128,
    "prefix_length": 0,
    "prompt": null,
    "query_template": null,
    "apply_chat_template": true,
    "image_width": 224,
    "image_height": 224,
    "image_format": "RGB",
    "image_num": 1,
    "dataset": "random",
    "dataset_path": null,
    "frequency_penalty": null,
    "repetition_penalty": null,
    "logprobs": null,
    "max_tokens": 1111,
    "min_tokens": 1111,
    "n_choices": null,
    "seed": 0,
    "stop": null,
    "stop_token_ids": null,
    "stream": true,
    "temperature": 0.0,
    "top_p": null,
    "top_k": null,
    "extra_args": {}
}
2025-08-12 10:08:38,099 - evalscope - ERROR - Exception in async function 'benchmark': Cannot import available module of AutoTokenizer in modelscope, or related packages(['transformers', 'peft', 'diffusers'])
Traceback (most recent call last):
  File "C:\Users\lenovo\anaconda3\Lib\site-packages\evalscope\perf\utils\handler.py", line 17, in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda3\Lib\site-packages\evalscope\perf\benchmark.py", line 182, in benchmark
    api_plugin = api_plugin_class(args)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda3\Lib\site-packages\evalscope\perf\plugin\api\openai_api.py", line 27, in __init__
    from modelscope import AutoTokenizer
  File "C:\Users\lenovo\anaconda3\Lib\site-packages\modelscope\utils\import_utils.py", line 440, in __getattr__
    value = self._extra_import_func(name)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda3\Lib\site-packages\modelscope\__init__.py", line 134, in try_import_from_hf
    raise ImportError(
ImportError: Cannot import available module of AutoTokenizer in modelscope, or related packages(['transformers', 'peft', 'diffusers'])
